# qzone_api.py

import base64
import datetime
import json
import re
import time
from http.cookies import SimpleCookie
from typing import Any

import aiohttp
from aiocqhttp import CQHttp

from astrbot.api import logger

from .post import Post
from .utils import normalize_images


# ---------- å·¥å…·å‡½æ•° ----------
def generate_gtk(skey: str) -> str:
    """ç”Ÿæˆ QQ ç©ºé—´ gtk"""
    hash_val = 5381
    for ch in skey:
        hash_val += (hash_val << 5) + ord(ch)
    return str(hash_val & 0x7FFFFFFF)


def parse_upload_result(payload: dict[str, Any]) -> tuple[str, str]:
    """ä»ä¸Šä¼ è¿”å›ä½“é‡Œæå– picbo ä¸ richval"""
    if payload.get("ret") != 0:
        raise RuntimeError("å›¾ç‰‡ä¸Šä¼ å¤±è´¥")

    data = payload["data"]
    picbo = data["url"].split("&bo=", 1)[1]

    richval = ",{},{},{},{},{},{},,{},{}".format(
        data["albumid"],
        data["lloc"],
        data["sloc"],
        data["type"],
        data["height"],
        data["width"],
        data["height"],
        data["width"],
    )
    return picbo, richval


class Qzone:
    """QQ ç©ºé—´ HTTP API å°è£…"""

    BASE_URL = "https://user.qzone.qq.com"
    H5_BASE_URL = "https://h5.qzone.qq.com"
    UPLOAD_IMAGE_URL = "https://up.qzone.qq.com/cgi-bin/upload/cgi_upload_image"
    EMOTION_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_publish_v6"
    VISITOR_URL = "https://h5.qzone.qq.com/proxy/domain/g.qzone.qq.com/cgi-bin/friendshow/cgi_get_visitor_more"
    DOLIKE_URL = "https://h5.qzone.qq.com/proxy/domain/w.qzone.qq.com/cgi-bin/likes/internal_dolike_app"
    LIST_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6"
    COMMENT_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_re_feeds"
    ZONE_LIST_URL = "https://user.qzone.qq.com/proxy/domain/ic2.qzone.qq.com/cgi-bin/feeds/feeds3_html_more"

    def __init__(self, client: CQHttp) -> None:
        self._session = aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(limit=100, ssl=False),
            timeout=aiohttp.ClientTimeout(total=10),
        )
        self.client = client
        self.skey = ""
        self.p_skey = ""
        self.uin = 0
        self.gtk2 = ""
        self.raw_cookies = {}
        self.headers = {}

    async def login(self) -> bool:
        """ç™»å½•QQç©ºé—´"""
        try:
            cookie_str = (
                await self.client.get_cookies(domain="user.qzone.qq.com")
            ).get("cookies", "")
            cookies = {k: v.value for k, v in SimpleCookie(cookie_str).items()}
            self.skey = cookies.get("skey", "")
            self.p_skey = cookies.get("p_skey", "")
            self.uin = int(cookies.get("uin", "0")[1:])
            self.gtk2 = generate_gtk(self.p_skey)
            self.raw_cookies = {
                "uin": f"o{self.uin}",
                "skey": self.skey,
                "p_skey": self.p_skey,
            }
            self.headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
                "referer": f"{self.BASE_URL}/{self.uin}",
                "origin": f"{self.BASE_URL}",
            }
            logger.info(f"Qzone ç™»å½•æˆåŠŸ: {cookies}")
            return True
        except Exception as e:
            logger.error(f"Qzone ç™»å½•å¤±è´¥: {e}")
            return False

    async def _request(
        self,
        method: str,
        url: str,
        *,
        params: dict[str, Any] | None = None,
        data: dict[str, Any] | None = None,
        headers: dict[str, str] | None = None,
        timeout: int = 10,
        retry_count: int = 0,
    ) -> dict:
        """aiohttp åŒ…è£…"""
        if retry_count > 3:  # é™åˆ¶é€’å½’æ·±åº¦
            raise RuntimeError("è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•æ¬¡æ•°è¿‡å¤š")

        if method.upper() not in ["GET", "POST", "PUT", "DELETE"]:
            raise ValueError(f"æ— æ•ˆçš„è¯·æ±‚æ–¹æ³•: {method}")

        async with self._session.request(
            method.upper(),
            url,
            params=params,
            data=data,
            headers=headers or self.headers,
            cookies=self.raw_cookies,
            timeout=aiohttp.ClientTimeout(total=timeout),
        ) as resp:
            if resp.status not in [200, 401, 403]:
                raise RuntimeError(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status}")
            resp_text = await resp.text()
            logger.debug(f"åŸå§‹æ•°æ®: {resp_text}")
            json_str = ""
            if m := re.search(
                r"callback\s*\(\s*([^{]*(\{.*\})[^)]*)\s*\)", resp_text, re.I | re.S
            ):
                json_str = m.group(2)
            else:
                json_str = resp_text[resp_text.find("{") : resp_text.rfind("}") + 1]

            try:
                parse_data = json.loads(json_str.strip() or resp_text)
                code = parse_data.get("code")
            except json.JSONDecodeError as e:
                logger.error(f"JSON è§£æé”™è¯¯: {e}")
                raise
            # é‡ç™»æœºåˆ¶
            if resp.status in [401, 403] or code == -3000:
                logger.warning("è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : -3000ï¼Œæ­£åœ¨å°è¯•é‡æ–°ç™»å½•QQç©ºé—´...")
                if not await self.login():
                    raise RuntimeError("é‡æ–°ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¯·æ±‚")
                return await self._request(
                    method,
                    url,
                    params=params,
                    data=data,
                    headers=headers or self.headers,
                    timeout=timeout,
                    retry_count=retry_count + 1,
                )
            if code != 0:
                return {"error": parse_data.get("message") or f"è¯·æ±‚å¤±è´¥[{code}]"}
            return parse_data


    async def _upload_image(self, image: bytes) -> dict:
        """ä¸Šä¼ å•å¼ å›¾ç‰‡"""
        return await self._request(
            method="POST",
            url=self.UPLOAD_IMAGE_URL,
            timeout=60,
            data={
                "filename": "filename",
                "uploadtype": "1",
                "albumtype": "7",
                "skey": self.skey,
                "uin": self.uin,
                "p_skey": self.p_skey,
                "output_type": "json",
                "base64": "1",
                "picfile": base64.b64encode(image).decode(),
            }
        )

    async def get_visitor(self) -> dict:
        """è·å–ä»Šæ—¥/æ€»è®¿å®¢æ•°"""
        return await self._request(
            method="GET",
            url=self.VISITOR_URL,
            params={
                "uin": self.uin,
                "mask": 7,
                "g_tk": self.gtk2,
                "page": 1,
                "fupdate": 1,
                "clear": 1,
            }
        )

    def parse_visitors(self, data: dict) -> str:
        """
        æŠŠ QQ ç©ºé—´è®¿å®¢æ¥å£çš„æ•°æ®è§£ææˆæ˜“è¯»æ–‡æœ¬ã€‚
        """
        lines = []

        # 1. ç»Ÿè®¡æ‘˜è¦
        lines.append(f"ğŸ“Š ä»Šæ—¥è®¿å®¢ï¼š{data.get('todaycount', 0)} äºº")
        lines.append(f"ğŸ“ˆ æœ€è¿‘ 30 å¤©è®¿å®¢ï¼š{data.get('totalcount', 0)} äºº")
        lines.append("")

        # 2. é€æ¡è®¿å®¢
        items = data.get("items", [])
        if not items:
            lines.append("æš‚æ— è®¿å®¢è®°å½•")
            return "\n".join(lines)

        lines.append("ğŸ‘€ æœ€è¿‘æ¥è®¿æ˜ç»†ï¼š")
        for idx, v in enumerate(items, 1):
            # åŸºæœ¬ä¿¡æ¯
            name = v.get("name", "åŒ¿å")
            # qq = v.get("uin", "0")
            ts = v.get("time", 0)
            dt = datetime.datetime.fromtimestamp(ts).strftime("%m-%d %H:%M")

            # æ¸ é“
            src_map = {
                0: "è®¿é—®ç©ºé—´",
                13: "æŸ¥çœ‹åŠ¨æ€",
                32: "æ‰‹æœºQQ",
                41: "å›½é™…ç‰ˆQQ/TIM",
            }
            src = src_map.get(v.get("src"), f"æœªçŸ¥({v.get('src')})")

            # é»„é’»
            yellow = v.get("yellow", -1)
            vip_info = f"(LV{yellow})" if yellow > 0 else ""

            # éšèº«
            hide = " (éšèº«)" if v.get("is_hide_visit") else ""

            lines.append(f"\nÂ·{dt}\n{name}{vip_info}{hide}{src}")

            # è¯´è¯´å¿«ç…§
            shuos = v.get("shuoshuoes", [])
            if shuos:
                title = shuos[0].get("name", "")
                lines.append(f"   â””â”€ è¯´è¯´ï¼š{title}")

            # å¸¦æ¥çš„äºº
            brought = v.get("uins", [])
            if brought:
                names = ",".join(u.get("name", "") for u in brought)
                lines.append(f"   â””â”€ å¸¦æ¥äº†{names}")

        return "\n".join(lines)

    async def publish(self, post: Post) -> dict:
        """å‘è¡¨è¯´è¯´, è¿”å›tid"""
        post_data: dict[str, Any] = {
            "syn_tweet_verson": "1",
            "paramstr": "1",
            "who": "1",
            "con": post.text,
            "feedversion": "1",
            "ver": "1",
            "ugc_right": "1",
            "to_sign": "0",
            "hostuin": self.uin,
            "code_version": "1",
            "format": "json",
            "qzreferrer": f"{self.BASE_URL}/{self.uin}",
        }
        if post.images:
            pic_bos, richvals = [], []
            imgs: list[bytes] = await normalize_images(post.images)
            for img in imgs:
                up_json = await self._upload_image(img)
                picbo, richval = parse_upload_result(up_json)
                pic_bos.append(picbo)
                richvals.append(richval)

            post_data.update(
                pic_bo=",".join(pic_bos),
                richtype="1",
                richval="\t".join(richvals),
            )

        return await self._request(
            method="POST",
            url=self.EMOTION_URL,
            params={"g_tk": self.gtk2, "uin": self.uin},
            data=post_data,
        )

    async def like(self, fid: str, target_id: str) -> dict:
        """
        ç‚¹èµæŒ‡å®šè¯´è¯´ã€‚

        Args:
            fid (str): è¯´è¯´çš„åŠ¨æ€IDã€‚
            target_id (str): ç›®æ ‡QQå·ã€‚

        """
        return await self._request(
            method="POST",
            url=self.DOLIKE_URL,
            params={
                "g_tk": self.gtk2,
            },
            data={
                "qzreferrer": f"{self.BASE_URL}/{self.uin}",  # æ¥æº
                "opuin": self.uin,  # æ“ä½œè€…QQ
                "unikey": f"{self.BASE_URL}/{target_id}/mood/{fid}",  # åŠ¨æ€å”¯ä¸€æ ‡è¯†
                "curkey": f"{self.BASE_URL}/{target_id}/mood/{fid}",  # è¦æ“ä½œçš„åŠ¨æ€å¯¹è±¡
                "appid": 311,  # åº”ç”¨ID(è¯´è¯´:311)
                "from": 1,  # æ¥æº
                "typeid": 0,  # ç±»å‹ID
                "abstime": int(time.time()),  # å½“å‰æ—¶é—´æˆ³
                "fid": fid,  # åŠ¨æ€ID
                "active": 0,  # æ´»åŠ¨ID
                "format": "json",  # è¿”å›æ ¼å¼
                "fupdate": 1,  # æ›´æ–°æ ‡è®°
            }
        )

    async def comment(self, fid: str, target_id: str, content: str) -> dict:
        """
        è¯„è®ºæŒ‡å®šè¯´è¯´ã€‚

        Args:
            fid (str): è¯´è¯´çš„åŠ¨æ€IDã€‚
            target_id (str): ç›®æ ‡QQå·ã€‚
            content (str): è¯„è®ºçš„æ–‡æœ¬å†…å®¹ã€‚

        """
        return await self._request(
            "POST",
            url=self.COMMENT_URL,
            params={"g_tk": self.gtk2},
            data={
                "topicId": f"{target_id}_{fid}__1",  # è¯´è¯´ID
                "uin": self.uin,  # botQQ
                "hostUin": target_id,  # ç›®æ ‡QQ
                "feedsType": 100,  # è¯´è¯´ç±»å‹
                "inCharset": "utf-8",  # å­—ç¬¦é›†
                "outCharset": "utf-8",  # å­—ç¬¦é›†
                "plat": "qzone",  # å¹³å°
                "source": "ic",  # æ¥æº
                "platformid": 52,  # å¹³å°id
                "format": "fs",  # è¿”å›æ ¼å¼
                "ref": "feeds",  # å¼•ç”¨
                "content": content,  # è¯„è®ºå†…å®¹
            }
        )

    def _get_comments(self, msg: dict) -> list[dict]:
        comments = []
        for comment in msg.get("commentlist") or []:
            comment_time = comment.get("createTime", "") or comment.get(
                "createTime2", ""
            )

            for sub_comment in comment.get("list_3") or []:
                sub_content = sub_comment.get("content", "")
                sub_nickname = sub_comment.get("name", "")
                sub_uin = sub_comment.get("uin", "")
                sub_tid_value = sub_comment.get("tid")
                sub_time = sub_comment.get("createTime", "") or comment.get(
                    "createTime2", ""
                )
                comments.append(
                    {
                        "content": sub_content,
                        "qq_account": str(sub_uin),
                        "nickname": sub_nickname,
                        "comment_tid": sub_tid_value,
                        "created_time": sub_time,
                        "parent_tid": comment.get("tid"),
                    }
                )

            comments.append(
                {
                    "content": comment.get("content", ""),
                    "qq_account": comment.get("uin", ""),
                    "nickname": comment.get("name", ""),
                    "comment_tid": comment.get("tid"),
                    "created_time": comment_time,
                    "parent_tid": None,
                }
            )
        return comments[::-1]

    async def get_posts(self, target_id: str, pos: int = 1, num: int = 1) -> dict:
        """
        è·å–æŒ‡å®šQQå·çš„å¥½å‹è¯´è¯´åˆ—è¡¨

        Args:
            target_id (str): ç›®æ ‡QQå·ã€‚
            pos (int): èµ·å§‹ä½ç½®ã€‚
            num (int): è¦è·å–çš„è¯´è¯´æ•°é‡ã€‚
        """
        logger.info(f"æ­£åœ¨è·å– {target_id} çš„è¯´è¯´åˆ—è¡¨...")
        return await self._request(
            method="GET",
            url=self.LIST_URL,
            params={
                "g_tk": self.gtk2,
                "uin": target_id,  # ç›®æ ‡QQ
                "ftype": 0,  # å…¨éƒ¨è¯´è¯´
                "sort": 0,  # æœ€æ–°åœ¨å‰
                "pos": pos,  # èµ·å§‹ä½ç½®
                "num": num,  # è·å–æ¡æ•°
                "replynum": 100,  # è¯„è®ºæ•°
                "callback": "_preloadCallback",
                "code_version": 1,
                "format": "json",
                "need_comment": 1,
                "need_private_comment": 1,
            }
        )

    def parse_posts(self, data: dict) -> list[Post]:
        """è§£æè¯´è¯´åˆ—è¡¨"""
        posts = []
        msglist = data.get("msglist") or []
        for msg in msglist:
            logger.debug(msg)
            # æå–å›¾ç‰‡ä¿¡æ¯
            image_urls = []
            for img_data in msg.get("pic", []):
                for key in ("url2", "url3", "url1", "smallurl"):
                    if raw := img_data.get(key):
                        image_urls.append(raw)
                        break
            # è¯»å–è§†é¢‘å°é¢ï¼ˆæŒ‰å›¾ç‰‡å¤„ç†ï¼‰
            for video in msg.get("video") or []:
                video_image_url = video.get("url1") or video.get("pic_url")
                image_urls.append(video_image_url)
            # æå–è§†é¢‘æ’­æ”¾åœ°å€
            video_urls = []
            for video in msg.get("video") or []:
                url = video.get("url3")
                if url:
                    video_urls.append(url)
            # æå–è½¬å‘å†…å®¹
            rt_con = msg.get("rt_con", {}).get("content", "")
            # æå–è¯„è®º
            comments = self._get_comments(msg)
            # æ„é€ Postå¯¹è±¡
            post = Post(
                tid=msg.get("tid", 0),
                uin=msg.get("uin", 0),
                name=msg.get("name", ""),
                gin=0,
                text=msg.get("content", "").strip(),
                images=image_urls,
                videos=video_urls,
                anon=False,
                status="approved",
                create_time=msg.get("created_time", 0),
                rt_con=rt_con,
                comments=comments,
                extra_text=msg.get("source_name"),
            )
            posts.append(post)

        return posts

    # async def delete(self, tid: str):
    #     """åˆ é™¤tidå¯¹åº”è¯´è¯´"""

    #     DELETE_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_delete_v6"
    #     return await self._request(
    #         "POST",
    #         url=DELETE_URL,
    #         params={"g_tk": self.gtk2},
    #         data={
    #             "tid": tid,
    #             "hostUin": self.uin,
    #             "qzreferrer": f"{self.BASE_URL}/{self.uin}",
    #             "t1_source": 1,
    #             "code_version": 1,
    #             "format": "fs",
    #         },
    #     )



    # async def monitor_get_qzones(self, self_readnum: int) -> list[dict[str, Any]]:
    #     """
    #     è·å–è‡ªå·±çš„å¥½å‹è¯´è¯´åˆ—è¡¨ï¼Œè¿”å›å·²è¯»ä¸æœªè¯»çš„è¯´è¯´åˆ—è¡¨ã€‚
    #     Args:
    #         self_readnum: éœ€è¦è·å–å®Œæ•´è¯„è®ºçš„è‡ªå·±çš„æœ€æ–°è¯´è¯´æ•°é‡

    #     """
    #     res = await self._request(
    #         method="GET",
    #         url=self.ZONE_LIST_URL,
    #         params={
    #             "uin": self.uin,  # QQå·
    #             "scope": 0,  # è®¿é—®èŒƒå›´
    #             "view": 1,  # æŸ¥çœ‹æƒé™
    #             "filter": "all",  # å…¨éƒ¨åŠ¨æ€
    #             "flag": 1,  # æ ‡è®°
    #             "applist": "all",  # æ‰€æœ‰åº”ç”¨
    #             "pagenum": 1,  # é¡µç 
    #             "aisortEndTime": 0,  # AIæ’åºç»“æŸæ—¶é—´
    #             "aisortOffset": 0,  # AIæ’åºåç§»
    #             "aisortBeginTime": 0,  # AIæ’åºå¼€å§‹æ—¶é—´
    #             "begintime": 0,  # å¼€å§‹æ—¶é—´
    #             "format": "json",  # è¿”å›æ ¼å¼
    #             "g_tk": self.gtk2,  # ä»¤ç‰Œ
    #             "useutf8": 1,  # ä½¿ç”¨UTF8ç¼–ç 
    #             "outputhtmlfeed": 1,  # è¾“å‡ºHTMLæ ¼å¼
    #         }
    #     )

    #     if res.get("code") != 0:
    #         raise Exception(f"è¯´è¯´è·å–å¤±è´¥: {res}")

    #     #return self.parse_qzone_list(res)
    #     print(res)
    #     try:
    #         feeds_list = []
    #         num_self = 0  # è®°å½•è‡ªå·±çš„è¯´è¯´æ•°é‡
    #         for feed in res:
    #             if not feed:  # è·³è¿‡Noneå€¼
    #                 continue
    #             # è¿‡æ»¤å¹¿å‘Šç±»å†…å®¹ï¼ˆappid=311ï¼‰
    #             appid = str(feed.get("appid", ""))
    #             if appid != "311":
    #                 continue
    #             target_qq = feed.get("uin", "")
    #             if target_qq == str(self.uin):
    #                 num_self += 1  # ç»Ÿè®¡è‡ªå·±çš„è¯´è¯´æ•°é‡
    #             tid = feed.get("key", "")
    #             if not target_qq or not tid:
    #                 logger.error(f"æ— æ•ˆçš„è¯´è¯´æ•°æ®: target_qq={target_qq}, tid={tid}")
    #                 continue
    #             # print(feed)

    #             html_content = feed.get("html", "")
    #             if not html_content:
    #                 logger.error(f"è¯´è¯´å†…å®¹ä¸ºç©º: UIN={target_qq}, TID={tid}")
    #                 continue

    #             soup = bs4.BeautifulSoup(html_content, "html.parser")

    #             # è§£æè¯´è¯´æ—¶é—´ - ç›¸å¯¹æ—¶é—´ï¼Œå¦‚'æ˜¨å¤©17:50'
    #             created_time = feed.get("feedstime", "").strip()

    #             # æå–æ–‡å­—å†…å®¹
    #             text_div = soup.find("div", class_="f-info")
    #             text = text_div.get_text(strip=True) if text_div else ""
    #             # æå–è½¬å‘å†…å®¹
    #             rt_con = ""
    #             txt_box = soup.select_one("div.txt-box")
    #             if txt_box:
    #                 # è·å–é™¤æ˜µç§°å¤–çš„çº¯æ–‡æœ¬å†…å®¹
    #                 rt_con = txt_box.get_text(strip=True)
    #                 # åˆ†å‰²æ‰æ˜µç§°éƒ¨åˆ†ï¼ˆä»ç¬¬ä¸€ä¸ªå†’å·å¼€å§‹å–å†…å®¹ï¼‰
    #                 if "ï¼š" in rt_con:
    #                     rt_con = rt_con.split("ï¼š", 1)[1].strip()
    #             # æå–å›¾ç‰‡URL
    #             image_urls = []
    #             # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡å®¹å™¨
    #             img_box = soup.find("div", class_="img-box")
    #             if img_box:
    #                 for img in img_box.find_all("img"):
    #                     src = img.get("src")
    #                     if src and not src.startswith(
    #                         "http://qzonestyle.gtimg.cn"
    #                     ):  # è¿‡æ»¤è¡¨æƒ…å›¾æ ‡
    #                         image_urls.append(src)
    #             # TODO ä¸´æ—¶è§†é¢‘å¤„ç†åŠæ³•ï¼ˆè§†é¢‘ç¼©ç•¥å›¾ï¼‰
    #             images = []
    #             img_tag = soup.select_one("div.video-img img")
    #             if img_tag and "src" in img_tag.attrs:
    #                 if img_tag["src"] not in images:
    #                     images.append(img_tag["src"])

    #             # è·å–è§†é¢‘url
    #             videos = []
    #             video_div = soup.select_one("div.img-box.f-video-wrap.play")
    #             if video_div and "url3" in video_div.attrs:
    #                 videos.append(video_div["url3"])
    #             # è·å–è¯„è®ºå†…å®¹
    #             comments_list = []
    #             # æŸ¥æ‰¾æ‰€æœ‰è¯„è®ºé¡¹ï¼ˆåŒ…æ‹¬ä¸»è¯„è®ºå’Œå›å¤ï¼‰
    #             comment_items = soup.select("li.comments-item.bor3")
    #             if comment_items:
    #                 for item in comment_items:
    #                     # æå–åŸºæœ¬ä¿¡æ¯
    #                     qq_account = item.get("data-uin", "")
    #                     comment_tid = item.get("data-tid", "")
    #                     nickname = item.get("data-nick", "")

    #                     # æŸ¥æ‰¾è¯„è®ºå†…å®¹
    #                     content_div = item.select_one("div.comments-content")
    #                     if content_div:
    #                         # ç§»é™¤æ“ä½œæŒ‰é’®ï¼ˆå›å¤/åˆ é™¤ï¼‰
    #                         for op in content_div.select("div.comments-op"):
    #                             op.decompose()
    #                         # è·å–çº¯æ–‡æœ¬å†…å®¹
    #                         content = content_div.get_text(" ", strip=True)
    #                     else:
    #                         content = ""

    #                     # æå–è¯„è®ºæ—¶é—´ï¼ˆç›´æ¥ä½¿ç”¨ç›¸å¯¹æ—¶é—´å­—ç¬¦ä¸²ï¼‰
    #                     comment_time_span = item.select_one("span.state")
    #                     comment_time = (
    #                         comment_time_span.get_text(strip=True)
    #                         if comment_time_span
    #                         else ""
    #                     )

    #                     # æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤
    #                     parent_tid = None
    #                     parent_div = item.find_parent("div", class_="mod-comments-sub")
    #                     if parent_div:
    #                         parent_li = parent_div.find_parent(
    #                             "li", class_="comments-item"
    #                         )
    #                         if parent_li:
    #                             parent_tid = parent_li.get("data-tid")

    #                     comments_list.append(
    #                         {
    #                             "qq_account": str(qq_account),
    #                             "nickname": nickname,
    #                             "comment_tid": int(comment_tid)
    #                             if comment_tid.isdigit()
    #                             else 0,
    #                             "content": content,
    #                             "created_time": comment_time,  # ç›´æ¥ä½¿ç”¨ç›¸å¯¹æ—¶é—´å­—ç¬¦ä¸²
    #                             "parent_tid": int(parent_tid)
    #                             if parent_tid and parent_tid.isdigit()
    #                             else None,
    #                         }
    #                     )

    #             feeds_list.append(
    #                 {
    #                     "target_qq": str(target_qq),
    #                     "tid": str(tid),
    #                     "created_time": created_time,  # ç›¸å¯¹æ—¶é—´å­—ç¬¦ä¸²
    #                     "content": text,
    #                     "images": images,
    #                     "videos": videos,
    #                     "rt_con": rt_con,
    #                     "comments": comments_list,
    #                 }
    #             )

    #         logger.info(
    #             f"æˆåŠŸè§£æ {len(feeds_list)} æ¡æœ€æ–°è¯´è¯´ï¼Œå…¶ä¸­è‡ªå·±çš„è¯´è¯´æœ‰ {num_self} æ¡"
    #         )
    #         # è·å–è‡ªå·±è¯´è¯´ä¸‹çš„å®Œæ•´è¯„è®ºå†…å®¹
    #         feeds_list = [
    #             item for item in feeds_list if item.get("target_qq") != str(self.uin)
    #         ]  # å»é™¤è‡ªå·±çš„è¯´è¯´
    #         self_feeds = await self.get_qzones(str(self.uin), self_readnum)
    #         feeds_list.extend(self_feeds)
    #         return feeds_list
    #     except Exception as e:
    #         logger.error(f"è§£æè¯´è¯´é”™è¯¯ï¼š{e}")
    #         return []

    async def terminate(self) -> None:
        await self._session.close()
