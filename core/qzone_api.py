# qzone_api.py

import base64
import datetime
import json
import re
import time
from http.cookies import SimpleCookie
from typing import Any

import aiohttp
import bs4
import json5
from aiocqhttp import CQHttp

from astrbot.api import logger

from .comment import Comment
from .post import Post
from .utils import normalize_images


class QzoneContext:
    """ç»Ÿä¸€å°è£… Qzone è¯·æ±‚æ‰€éœ€çš„æ‰€æœ‰åŠ¨æ€å‚æ•°"""

    def __init__(self, uin: int, skey: str, p_skey: str):
        self.uin = uin
        self.skey = skey
        self.p_skey = p_skey

    @property
    def gtk2(self) -> str:
        """åŠ¨æ€è®¡ç®— gtk2"""
        hash_val = 5381
        for ch in self.p_skey:
            hash_val += (hash_val << 5) + ord(ch)
        return str(hash_val & 0x7FFFFFFF)

    def cookies(self) -> dict[str, str]:
        return {
            "uin": f"o{self.uin}",
            "skey": self.skey,
            "p_skey": self.p_skey,
        }

    def headers(self) -> dict[str, str]:
        return {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
            "referer": f"https://user.qzone.qq.com/{self.uin}",
            "origin": "https://user.qzone.qq.com",
            "Host": "user.qzone.qq.com",
            "Connection": "keep-alive",
        }


class Qzone:
    """QQ ç©ºé—´ HTTP API å°è£…"""

    BASE_URL = "https://user.qzone.qq.com"
    UPLOAD_IMAGE_URL = "https://up.qzone.qq.com/cgi-bin/upload/cgi_upload_image"
    EMOTION_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_publish_v6"
    DOLIKE_URL = "https://user.qzone.qq.com/proxy/domain/w.qzone.qq.com/cgi-bin/likes/internal_dolike_app"
    LIST_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6"
    COMMENT_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_re_feeds"
    ZONE_LIST_URL = "https://user.qzone.qq.com/proxy/domain/ic2.qzone.qq.com/cgi-bin/feeds/feeds3_html_more"
    VISITOR_URL = "https://h5.qzone.qq.com/proxy/domain/g.qzone.qq.com/cgi-bin/friendshow/cgi_get_visitor_more"
    REPLY_URL = "https://h5.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_re_feeds"
    DELETE_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_delete_v6"
    DETAIL_URL = "https://h5.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msgdetail_v6"

    def __init__(self, client: CQHttp) -> None:
        self._session = aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(limit=100, ssl=False),
            timeout=aiohttp.ClientTimeout(total=10),
        )
        self.client = client
        self.ctx: QzoneContext = None  # type: ignore

    async def login(self) -> bool:
        logger.info("æ­£åœ¨ç™»å½•QQç©ºé—´...")
        try:
            cookie_str = (
                await self.client.get_cookies(domain="user.qzone.qq.com")
            ).get("cookies", "")
            c = {k: v.value for k, v in SimpleCookie(cookie_str).items()}
            uin = int(c.get("uin", "0")[1:])
            if not uin:
                raise RuntimeError("Cookie ä¸­ç¼ºå°‘åˆæ³• uin")
            self.ctx = QzoneContext(
                uin=uin, skey=c.get("skey", ""), p_skey=c.get("p_skey", "")
            )
            logger.info(f"ç™»å½•æˆåŠŸï¼Œuin={uin}")
            return True
        except Exception as e:
            logger.error(f"ç™»å½•å¤±è´¥: {e}")
            return False

    async def ready(self):
        """å‡†å¤‡å¥½ç™»å½•çŠ¶æ€"""
        if not self.ctx:
            await self.login()

    async def _request(
        self,
        method: str,
        url: str,
        *,
        params: dict[str, Any] | None = None,
        data: dict[str, Any] | None = None,
        headers: dict[str, str] | None = None,
        timeout: int = 10,
        retry_count: int = 0,
        debug: bool = False,
    ) -> tuple[bool, dict]:
        """aiohttp åŒ…è£…"""
        if retry_count > 2:  # é™åˆ¶é€’å½’æ·±åº¦
            raise RuntimeError("è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•æ¬¡æ•°è¿‡å¤š")

        if method.upper() not in ["GET", "POST", "PUT", "DELETE"]:
            raise ValueError(f"æ— æ•ˆçš„è¯·æ±‚æ–¹æ³•: {method}")

        # å‘èµ·è¯·æ±‚
        async with self._session.request(
            method.upper(),
            url,
            params=params,
            data=data,
            headers=headers or self.ctx.headers(),
            cookies=self.ctx.cookies(),
            timeout=aiohttp.ClientTimeout(total=timeout),
        ) as resp:
            # çŠ¶æ€ç å¤„ç†
            if resp.status not in [200, 401, 403]:
                raise RuntimeError(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status}")

            # å¤„ç†å“åº”æ•°æ®
            resp_text = await resp.text()
            if debug:
                logger.debug(f"å“åº”æ•°æ®: {resp_text}")

            # å°è¯•è§£æ JSON
            json_str = ""
            if m := re.search(
                r"callback\s*\(\s*([^{]*(\{.*\})[^)]*)\s*\)", resp_text, re.I | re.S
            ):
                json_str = m.group(2)
            else:
                json_str = resp_text[resp_text.find("{") : resp_text.rfind("}") + 1]
            json_str = json_str.replace("undefined", "null")
            try:
                parse_data = json5.loads(json_str.strip())
                if not isinstance(parse_data, dict):
                    raise RuntimeError("JSON è§£æç»“æœä¸æ˜¯å­—å…¸ç±»å‹")
                if debug:
                    logger.debug(f"è§£ææ•°æ®: {parse_data}")
            except json.JSONDecodeError as e:
                logger.error(f"JSON è§£æé”™è¯¯: {e}")
                raise

            # é‡ç™»æœºåˆ¶
            code = parse_data.get("code")
            if resp.status in [401, 403] or code == -3000:
                logger.warning(
                    f"è¯·æ±‚å¤±è´¥: {resp.status}ï¼Œè§£ææ•°æ®: {parse_data}, æ­£åœ¨å°è¯•é‡æ–°ç™»å½•QQç©ºé—´..."
                )
                if not await self.login():
                    raise RuntimeError("é‡æ–°ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¯·æ±‚")
                # âœ… é‡æ–°æ„é€ å‚æ•°ï¼ˆæ­¤æ—¶ self.ctx å·²æ›´æ–°ï¼‰
                if params:
                    params["g_tk"] = self.ctx.gtk2
                    if "uin" in params:
                        params["uin"] = self.ctx.uin
                if data:
                    data["p_skey"] = self.ctx.p_skey
                    data["skey"] = self.ctx.skey
                    if "uin" in data:
                        data["uin"] = self.ctx.uin
                return await self._request(
                    method,
                    url,
                    params=params,
                    data=data,
                    headers=headers or self.ctx.headers(),
                    timeout=timeout,
                    retry_count=retry_count + 1,
                )
            if code != 0:
                return False, {"code": code, "message": parse_data.get("message")}
            return True, parse_data

    async def _upload_image(self, image: bytes) -> dict:
        """ä¸Šä¼ å•å¼ å›¾ç‰‡"""
        await self.ready()
        succ, data = await self._request(
            method="POST",
            url=self.UPLOAD_IMAGE_URL,
            timeout=60,
            data={
                "filename": "filename",
                "uploadtype": "1",
                "albumtype": "7",
                "skey": self.ctx.skey,
                "uin": self.ctx.uin,
                "p_skey": self.ctx.p_skey,
                "output_type": "json",
                "base64": "1",
                "picfile": base64.b64encode(image).decode(),
            },
        )
        if not succ:
            raise RuntimeError("å›¾ç‰‡ä¸Šä¼ å¤±è´¥")
        return data

    async def get_visitor(self) -> str:
        """è·å–è®¿å®¢æ•°"""
        await self.ready()
        succ, data = await self._request(
            method="GET",
            url=self.VISITOR_URL,
            params={
                "uin": self.ctx.uin,
                "mask": 7,
                "g_tk": self.ctx.gtk2,
                "page": 1,
                "fupdate": 1,
                "clear": 1,
            },
        )
        return self.parse_visitors(data) if succ else str(data)

    @staticmethod
    def parse_upload_result(payload: dict[str, Any]) -> tuple[str, str]:
        """ä»ä¸Šä¼ è¿”å›ä½“é‡Œæå– picbo ä¸ richval"""
        if payload.get("ret") != 0:
            raise RuntimeError("å›¾ç‰‡ä¸Šä¼ å¤±è´¥")

        data = payload["data"]
        picbo = data["url"].split("&bo=", 1)[1]

        richval = ",{},{},{},{},{},{},,{},{}".format(
            data["albumid"],
            data["lloc"],
            data["sloc"],
            data["type"],
            data["height"],
            data["width"],
            data["height"],
            data["width"],
        )
        return picbo, richval

    async def publish(self, post: Post) -> tuple[bool, dict]:
        """å‘è¡¨è¯´è¯´, è¿”å›tid"""
        await self.ready()
        post_data: dict[str, Any] = {
            "syn_tweet_verson": "1",
            "paramstr": "1",
            "who": "1",
            "con": post.text,
            "feedversion": "1",
            "ver": "1",
            "ugc_right": "1",
            "to_sign": "0",
            "hostuin": self.ctx.uin,
            "code_version": "1",
            "format": "json",
            "qzreferrer": f"{self.BASE_URL}/{self.ctx.uin}",
        }
        if post.images:
            pic_bos, richvals = [], []
            imgs: list[bytes] = await normalize_images(post.images)
            for img in imgs:
                up_json = await self._upload_image(img)
                picbo, richval = self.parse_upload_result(up_json)
                pic_bos.append(picbo)
                richvals.append(richval)

            post_data.update(
                pic_bo=",".join(pic_bos),
                richtype="1",
                richval="\t".join(richvals),
            )

        return await self._request(
            method="POST",
            url=self.EMOTION_URL,
            params={"g_tk": self.ctx.gtk2, "uin": self.ctx.uin},
            data=post_data,
        )

    async def like(self, tid: str, target_id: str) -> tuple[bool, dict]:
        """
        ç‚¹èµæŒ‡å®šè¯´è¯´ã€‚

        Args:
            fid (str): è¯´è¯´çš„åŠ¨æ€IDã€‚
            target_id (str): ç›®æ ‡QQå·ã€‚

        """
        await self.ready()
        return await self._request(
            method="POST",
            url=self.DOLIKE_URL,
            params={
                "g_tk": self.ctx.gtk2,
            },
            data={
                "qzreferrer": f"{self.BASE_URL}/{self.ctx.uin}",  # æ¥æº
                "opuin": self.ctx.uin,  # æ“ä½œè€…QQ
                "unikey": f"{self.BASE_URL}/{target_id}/mood/{tid}",  # åŠ¨æ€å”¯ä¸€æ ‡è¯†
                "curkey": f"{self.BASE_URL}/{target_id}/mood/{tid}",  # è¦æ“ä½œçš„åŠ¨æ€å¯¹è±¡
                "appid": 311,  # åº”ç”¨ID(è¯´è¯´:311)
                "from": 1,  # æ¥æº
                "typeid": 0,  # ç±»å‹ID
                "abstime": int(time.time()),  # å½“å‰æ—¶é—´æˆ³
                "fid": tid,  # åŠ¨æ€ID
                "active": 0,  # æ´»åŠ¨ID
                "format": "json",  # è¿”å›æ ¼å¼
                "fupdate": 1,  # æ›´æ–°æ ‡è®°
            },
        )

    async def comment(
        self, fid: str, target_id: str, content: str
    ) -> tuple[bool, dict]:
        """
        è¯„è®ºæŒ‡å®šè¯´è¯´ã€‚

        Args:
            fid (str): è¯´è¯´çš„åŠ¨æ€IDã€‚
            target_id (str): ç›®æ ‡QQå·ã€‚
            content (str): è¯„è®ºçš„æ–‡æœ¬å†…å®¹ã€‚

        """
        await self.ready()
        return await self._request(
            "POST",
            url=self.COMMENT_URL,
            params={"g_tk": self.ctx.gtk2},
            data={
                "topicId": f"{target_id}_{fid}__1",  # è¯´è¯´ID
                "uin": self.ctx.uin,  # botQQ
                "hostUin": target_id,  # ç›®æ ‡QQ
                "feedsType": 100,  # è¯´è¯´ç±»å‹
                "inCharset": "utf-8",  # å­—ç¬¦é›†
                "outCharset": "utf-8",  # å­—ç¬¦é›†
                "plat": "qzone",  # å¹³å°
                "source": "ic",  # æ¥æº
                "platformid": 52,  # å¹³å°id
                "format": "fs",  # è¿”å›æ ¼å¼
                "ref": "feeds",  # å¼•ç”¨
                "content": content,  # è¯„è®ºå†…å®¹
            },
        )

    async def delete(self, tid: str):
        """åˆ é™¤tidå¯¹åº”è¯´è¯´ï¼ˆæ¥å£æš‚æ—¶æœªæ¥é€šï¼‰"""
        await self.ready()
        referer = f"https://user.qzone.qq.com/{self.ctx.uin}/mood/{tid}"
        return await self._request(
            "POST",
            url=self.DELETE_URL,
            params={"g_tk": self.ctx.gtk2},
            data={
                "tid": tid,
                "hostUin": self.ctx.uin,
                "qzreferrer": referer,
                "t1_source": 1,
                "code_version": 1,
                "format": "fs",
                "p_skey": self.ctx.p_skey,
            },
            headers={**self.ctx.headers(), "referer": referer},
        )

    async def get_feeds(
        self, target_id: str, pos: int = 1, num: int = 1
    ) -> tuple[bool, list[Post] | str]:
        """
        è·å–æŒ‡å®šQQå·çš„å¥½å‹è¯´è¯´åˆ—è¡¨

        Args:
            target_id (str): ç›®æ ‡QQå·ã€‚
            pos (int): èµ·å§‹ä½ç½®ã€‚
            num (int): è¦è·å–çš„è¯´è¯´æ•°é‡ã€‚
        """
        await self.ready()
        logger.info(f"æ­£åœ¨è·å– {target_id} çš„è¯´è¯´åˆ—è¡¨...")
        succ, data = await self._request(
            method="GET",
            url=self.LIST_URL,
            params={
                "g_tk": self.ctx.gtk2,
                "uin": target_id,  # ç›®æ ‡QQ
                "ftype": 0,  # å…¨éƒ¨è¯´è¯´
                "sort": 0,  # æœ€æ–°åœ¨å‰
                "pos": pos,  # èµ·å§‹ä½ç½®
                "num": num,  # è·å–æ¡æ•°
                "replynum": 100,  # è¯„è®ºæ•°
                "callback": "_preloadCallback",
                "code_version": 1,
                "format": "json",
                "need_comment": 1,
                "need_private_comment": 1,
            },
        )
        msglist = data.get("msglist", [])
        return succ, self.parse_feeds(msglist) if succ else data["message"]

    async def get_detail(self, post: Post) -> Post:
        """
        è·å–å•æ¡è¯´è¯´è¯¦æƒ…ï¼ˆå«å®Œæ•´è¯„è®ºã€è½¬å‘ã€å›¾ç‰‡ã€è§†é¢‘ç­‰ï¼‰

        Args:
            uin: ç›®æ ‡ QQ å·
            tid: è¯´è¯´ idï¼ˆå¯¹åº” msglist é‡Œçš„ tidï¼‰

        Returns:
            (True, Post) æˆ– (False, é”™è¯¯ä¿¡æ¯)
        """
        await self.ready()
        succ, data = await self._request(
            "GET",
            self.DETAIL_URL,
            params={
                "uin": post.uin,
                "tid": post.tid,
                "format": "jsonp",
                "g_tk": self.ctx.gtk2,
            },
        )
        if succ:
            if posts := self.parse_feeds([data]):
                return posts[0]

        logger.warning(f"è·å–è¯´è¯´è¯¦æƒ…å¤±è´¥ï¼š{data}")
        return post

    async def get_recent_feeds(self, page: int = 1) -> tuple[bool, list[Post] | str]:
        """
        è·å–è‡ªå·±çš„å¥½å‹è¯´è¯´åˆ—è¡¨ï¼Œè¿”å›å·²è¯»ä¸æœªè¯»çš„è¯´è¯´åˆ—è¡¨
        """
        page = 1  # æµ‹è¯•æ—¶å‘ç°æš‚æ—¶æ˜¯æ— æ•ˆé…ç½®ï¼Œå…ˆè®¾ä¸º1å§
        await self.ready()
        succ, data = await self._request(
            method="GET",
            url=self.ZONE_LIST_URL,
            params={
                "uin": self.ctx.uin,  # QQå·
                "scope": 0,  # è®¿é—®èŒƒå›´
                "view": 1,  # æŸ¥çœ‹æƒé™
                "filter": "all",  # å…¨éƒ¨åŠ¨æ€
                "flag": 1,  # æ ‡è®°
                "applist": "all",  # æ‰€æœ‰åº”ç”¨
                "pagenum": page,  # é¡µç 
                "aisortEndTime": 0,  # AIæ’åºç»“æŸæ—¶é—´
                "aisortOffset": 0,  # AIæ’åºåç§»
                "aisortBeginTime": 0,  # AIæ’åºå¼€å§‹æ—¶é—´
                "begintime": 0,  # å¼€å§‹æ—¶é—´
                "format": "json",  # è¿”å›æ ¼å¼
                "g_tk": self.ctx.gtk2,  # ä»¤ç‰Œ
                "useutf8": 1,  # ä½¿ç”¨UTF8ç¼–ç 
                "outputhtmlfeed": 1,  # è¾“å‡ºHTMLæ ¼å¼
            },
        )
        return succ, self.parse_recent_feeds(data) if succ else data["message"]

    @staticmethod
    def parse_visitors(data: dict) -> str:
        """
        æŠŠ QQ ç©ºé—´è®¿å®¢æ¥å£çš„æ•°æ®è§£ææˆæ˜“è¯»æ–‡æœ¬ã€‚
        """
        lines = []

        # 1. ç»Ÿè®¡æ‘˜è¦
        lines.append(f"ğŸ“Š ä»Šæ—¥è®¿å®¢ï¼š{data.get('todaycount', 0)} äºº")
        lines.append(f"ğŸ“ˆ æœ€è¿‘ 30 å¤©è®¿å®¢ï¼š{data.get('totalcount', 0)} äºº")
        lines.append("")

        # 2. é€æ¡è®¿å®¢
        items = data.get("items", [])
        if not items:
            lines.append("æš‚æ— è®¿å®¢è®°å½•")
            return "\n".join(lines)

        lines.append("ğŸ‘€ æœ€è¿‘æ¥è®¿æ˜ç»†ï¼š")
        for idx, v in enumerate(items, 1):
            # åŸºæœ¬ä¿¡æ¯
            name = v.get("name", "åŒ¿å")
            # qq = v.get("uin", "0")
            ts = v.get("time", 0)
            dt = datetime.datetime.fromtimestamp(ts).strftime("%m-%d %H:%M")

            # æ¸ é“
            src_map = {
                0: "è®¿é—®ç©ºé—´",
                13: "æŸ¥çœ‹åŠ¨æ€",
                32: "æ‰‹æœºQQ",
                41: "å›½é™…ç‰ˆQQ/TIM",
            }
            src = src_map.get(v.get("src"), f"æœªçŸ¥({v.get('src')})")

            # é»„é’»
            yellow = v.get("yellow", -1)
            vip_info = f"(LV{yellow})" if yellow > 0 else ""

            # éšèº«
            hide = " (éšèº«)" if v.get("is_hide_visit") else ""

            lines.append(f"\nÂ·{dt}\n{name}{vip_info}{hide}{src}")

            # è¯´è¯´å¿«ç…§
            shuos = v.get("shuoshuoes", [])
            if shuos:
                title = shuos[0].get("name", "")
                lines.append(f"   â””â”€ è¯´è¯´ï¼š{title}")

            # å¸¦æ¥çš„äºº
            brought = v.get("uins", [])
            if brought:
                names = ",".join(u.get("name", "") for u in brought)
                lines.append(f"   â””â”€ å¸¦æ¥äº†{names}")

        return "\n".join(lines)

    def parse_feeds(self, msglist: list[dict]) -> list[Post]:
        """è§£æè¯´è¯´åˆ—è¡¨"""
        try:
            posts = []
            for msg in msglist:
                logger.debug(msg)
                # æå–å›¾ç‰‡ä¿¡æ¯
                image_urls = []
                for img_data in msg.get("pic", []):
                    for key in ("url2", "url3", "url1", "smallurl"):
                        if raw := img_data.get(key):
                            image_urls.append(raw)
                            break
                # è¯»å–è§†é¢‘å°é¢ï¼ˆæŒ‰å›¾ç‰‡å¤„ç†ï¼‰
                for video in msg.get("video") or []:
                    video_image_url = video.get("url1") or video.get("pic_url")
                    image_urls.append(video_image_url)
                # æå–è§†é¢‘æ’­æ”¾åœ°å€
                video_urls = []
                for video in msg.get("video") or []:
                    url = video.get("url3")
                    if url:
                        video_urls.append(url)
                # æå–è½¬å‘å†…å®¹
                rt_con = msg.get("rt_con", {}).get("content", "")
                # æå–è¯„è®º
                comments = Comment.build_list(msg.get("commentlist") or [])
                # æ„é€ Postå¯¹è±¡
                post = Post(
                    tid=msg.get("tid", 0),
                    uin=msg.get("uin", 0),
                    name=msg.get("name", ""),
                    gin=0,
                    text=msg.get("content", "").strip(),
                    images=image_urls,
                    videos=video_urls,
                    anon=False,
                    status="approved",
                    create_time=msg.get("created_time", 0),
                    rt_con=rt_con,
                    comments=comments,
                    extra_text=msg.get("source_name"),
                )
                posts.append(post)

            return posts

        except Exception as e:
            logger.error(f"è§£æè¯´è¯´åˆ—è¡¨å¤±è´¥: {e}")
            return []

    @staticmethod
    def parse_recent_feeds(data: dict) -> list[Post]:
        """è§£ææœ€è¿‘è¯´è¯´åˆ—è¡¨"""
        feeds: list = data.get("data", {}).get("data", {})
        if not data:
            return []
        try:
            posts = []
            for feed in feeds:
                if not feed:
                    continue
                # è¿‡æ»¤å¹¿å‘Šç±»å†…å®¹ï¼ˆappid=311ï¼‰
                appid = str(feed.get("appid", ""))
                if appid != "311":
                    continue
                uin = feed.get("uin", "")
                tid = feed.get("key", "")
                if not uin or not tid:
                    logger.error(f"æ— æ•ˆçš„è¯´è¯´æ•°æ®: target_qq={uin}, tid={tid}")
                    continue
                create_time = feed.get("abstime", "")
                nickname = feed.get("nickname", "")
                html_content = feed.get("html", "")
                if not html_content:
                    logger.error(f"è¯´è¯´å†…å®¹ä¸ºç©º: UIN={uin}, TID={tid}")
                    continue

                soup = bs4.BeautifulSoup(html_content, "html.parser")

                # æå–æ–‡å­—å†…å®¹
                text_div = soup.find("div", class_="f-info")
                text = text_div.get_text(strip=True) if text_div else ""
                # æå–è½¬å‘å†…å®¹
                rt_con = ""
                txt_box = soup.select_one("div.txt-box")
                if txt_box:
                    # è·å–é™¤æ˜µç§°å¤–çš„çº¯æ–‡æœ¬å†…å®¹
                    rt_con = txt_box.get_text(strip=True)
                    # åˆ†å‰²æ‰æ˜µç§°éƒ¨åˆ†ï¼ˆä»ç¬¬ä¸€ä¸ªå†’å·å¼€å§‹å–å†…å®¹ï¼‰
                    if "ï¼š" in rt_con:
                        rt_con = rt_con.split("ï¼š", 1)[1].strip()
                # æå–å›¾ç‰‡URL
                image_urls = []
                # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡å®¹å™¨
                if img_box := soup.find("div", class_="img-box"):
                    for img in img_box.find_all("img"):  # type: ignore
                        src = img.get("src")  # type: ignore
                        if src and not str(src).startswith(
                            "http://qzonestyle.gtimg.cn"
                        ):  # è¿‡æ»¤è¡¨æƒ…å›¾æ ‡
                            image_urls.append(src)
                # TODO ä¸´æ—¶è§†é¢‘å¤„ç†åŠæ³•ï¼ˆè§†é¢‘ç¼©ç•¥å›¾ï¼‰
                img_tag = soup.select_one("div.video-img img")
                if img_tag and "src" in img_tag.attrs:
                    image_urls.append(img_tag["src"])
                # è·å–è§†é¢‘url
                videos = []
                video_div = soup.select_one("div.img-box.f-video-wrap.play")
                if video_div and "url3" in video_div.attrs:
                    videos.append(video_div["url3"])
                # è·å–è¯„è®ºå†…å®¹
                comments: list[Comment] = []
                # æŸ¥æ‰¾æ‰€æœ‰è¯„è®ºé¡¹ï¼ˆåŒ…æ‹¬ä¸»è¯„è®ºå’Œå›å¤ï¼‰
                comment_items = soup.select("li.comments-item.bor3")
                if comment_items:
                    for item in comment_items:
                        # æå–åŸºæœ¬ä¿¡æ¯
                        data_uin = str(item.get("data-uin", ""))
                        comment_tid = str(item.get("data-tid", ""))
                        nickname = str(item.get("data-nick", ""))

                        # æŸ¥æ‰¾è¯„è®ºå†…å®¹
                        content_div = item.select_one("div.comments-content")
                        if content_div:
                            # ç§»é™¤æ“ä½œæŒ‰é’®ï¼ˆå›å¤/åˆ é™¤ï¼‰
                            for op in content_div.select("div.comments-op"):
                                op.decompose()
                            # è·å–çº¯æ–‡æœ¬å†…å®¹
                            content = content_div.get_text(" ", strip=True).split(
                                ":", 1
                            )[-1]
                        else:
                            content = ""

                        # æå–è¯„è®ºæ—¶é—´ï¼ˆç›´æ¥ä½¿ç”¨ç›¸å¯¹æ—¶é—´å­—ç¬¦ä¸²ï¼‰
                        comment_time_span = item.select_one("span.state")
                        comment_time = (
                            comment_time_span.get_text(strip=True)
                            if comment_time_span
                            else ""
                        )

                        # æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤
                        parent_tid = None
                        parent_div = item.find_parent("div", class_="mod-comments-sub")
                        if parent_div:
                            parent_li = parent_div.find_parent(
                                "li", class_="comments-item"
                            )
                            if parent_li:
                                parent_tid = str(parent_li.get("data-tid"))  # type: ignore

                        comments.append(
                            Comment(
                                uin=int(data_uin) if data_uin.isdigit() else 0,
                                nickname=nickname,
                                content=content,
                                create_time=0,
                                create_time_str=comment_time,
                                tid=int(comment_tid) if comment_tid.isdigit() else 0,
                                parent_tid=int(parent_tid)
                                if parent_tid and parent_tid.isdigit()
                                else None,
                            )
                        )
                # æ„é€ Postå¯¹è±¡
                post = Post(
                    tid=str(tid),
                    uin=int(uin),
                    name=str(nickname),
                    text=text,
                    images=list(set(image_urls)),
                    videos=videos,
                    create_time=create_time,
                    rt_con=rt_con,
                    comments=comments,
                )
                posts.append(post)

            logger.info(f"æˆåŠŸè§£æ {len(posts)} æ¡æœ€æ–°è¯´è¯´")
            return posts
        except Exception as e:
            logger.error(f"è§£æè¯´è¯´é”™è¯¯ï¼š{e}")
            return []

    async def terminate(self) -> None:
        await self._session.close()
